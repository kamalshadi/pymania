{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of new new algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Constantine': <class 'pymania.solvers.constantine.Constantine'>, 'MRP_F': <class 'pymania.solvers.mrp_symm_force.MRP_F'>, 'MRP_NF': <class 'pymania.solvers.mrp_symm_noforce.MRP_NF'>, 'Solver': <class 'pymania.solvers.base.Solver'>}\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from ipywidgets import interact, interactive\n",
    "from py2neo import Node, Relationship, Graph\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.stats import binom\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import pymania as mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "graph = Graph(host=\"canopus.cc.gatech.edu\",password='1234')\n",
    "sub_train = [126426, 137431, 144125, 146735, 152427, 153227, 177140, 180533, 186545, 188145]\n",
    "sub_test  = [206323, 227533, 248238, 360030, 361234, 362034, 368753, 401422, 413934, 453542]\n",
    "\n",
    "run_id_dense = \"Constantine_dense_v2\"\n",
    "run_id_sparse = \"Constantine_sparse_v2\"\n",
    "run_id_vdense = \"Constantine_vdense_v2\"\n",
    "run_id_vsparse = \"Constantine_vsparse_v2\"\n",
    "run_id_all = [run_id_dense, run_id_sparse, run_id_vdense, run_id_vsparse]\n",
    "run_label = {\"Constantine_dense_v2\":\"Dense\", \"Constantine_sparse_v2\":\"Sparse\", \n",
    "             \"Constantine_vdense_v2\":\"Very Dense\", \"Constantine_vsparse_v2\":\"Very Sparse\"}\n",
    "\n",
    "all_subjects = sub_train + sub_test\n",
    "n_train, n_test = len(sub_train), len(sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joini(lst):\n",
    "    return ', '.join(str(x) for x in lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Mania on all Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(subjects, run_type):\n",
    "    network = mn.create_project('Constantine', run_type)\n",
    "    for roi in ['L'+str(xx) for xx in range(1,181)]:\n",
    "        network.add_roi(roi)\n",
    "    for subject in subjects:\n",
    "        network.add_subject(subject)\n",
    "    network.load()\n",
    "    network.run()\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_network = get_network(sub_train, 'dense_temp')\n",
    "sparse_network = get_network(sub_train, 'sparse_temp')\n",
    "vdense_network = get_network(sub_train, 'vdense_temp')\n",
    "vsparse_network = get_network(sub_train, 'vsparse_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = {'dense':dense_network, 'sparse':sparse_network, 'vdense':vdense_network, 'vsparse':vsparse_network}\n",
    "suffixes = ['vsparse', 'sparse', 'dense', 'vdense']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Density and it's Consistency across subjects\n",
    "First, we try to see the total network density over all subjects and the consistency across each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.is_connected=TRUE AND \"\n",
    "query += f\"r.run_id IN {run_id_all} WITH r.run_id as run_id, COUNT(*) AS connections, COUNT(DISTINCT r.SUBJECT) AS num_sub, AVG(r.threshold2) as mean2 \"\n",
    "query += \"RETURN run_id, num_sub, connections*100.0/(32220.0*num_sub) as density, AVG(mean2) as threshold\"\n",
    "densities = graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Method</th><th># Subjects</th><th>Avg. Threshold</th><th>Density</th></tr><tr><td>Very Sparse</td><td>20</td><td>3228.15</td><td> 3.10%</td></tr><tr><td>Dense</td><td>20</td><td>  44.23</td><td>23.82%</td></tr><tr><td>Very Dense</td><td>20</td><td>  85.35</td><td>27.14%</td></tr><tr><td>Sparse</td><td>20</td><td> 516.05</td><td>11.72%</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = '<table><tr><th>Method</th><th># Subjects</th><th>Avg. Threshold</th><th>Density</th></tr>'\n",
    "for index, row in densities.iterrows():\n",
    "    html += f\"<tr><td>{run_label[row['run_id']]}</td><td>{row['num_sub']}</td>\"\n",
    "    html += \"<td>%7.2f</td><td>%5.2f%%</td></tr>\" % (row['threshold'], row['density'])\n",
    "html += '</table>'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_thresholds(run_id, subjects):\n",
    "    query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.is_connected=TRUE AND \"\n",
    "    query += f\" r.SUBJECT IN {subjects} AND r.run_id='{run_id}'  \"\n",
    "    query += \"WITH r.SUBJECT as subject, COUNT(*) AS connections, AVG(r.threshold2) as threshold \"\n",
    "    query += \"RETURN subject, connections, connections*100.0/32220.0 as percentage, threshold ORDER BY percentage\"\n",
    "    return graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_thresholds = get_subject_thresholds(run_id_dense, sub_train)\n",
    "sparse_thresholds = get_subject_thresholds(run_id_sparse, sub_train)\n",
    "vdense_thresholds = get_subject_thresholds(run_id_vdense, sub_train)\n",
    "vsparse_thresholds = get_subject_thresholds(run_id_vsparse, sub_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = dense_thresholds.merge(sparse_thresholds, how='inner', on=['subject'], suffixes=('_dense', '_sparse'))\n",
    "threshold2 = vdense_thresholds.merge(vsparse_thresholds, how='inner', on=['subject'], suffixes=('_vdense', '_vsparse'))\n",
    "thresholds = threshold1.merge(threshold2, how='inner', on=['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th rowspan=\"2\" align=\"center\" >Subject</th><th colspan=\"3\">Very Sparse</th><th colspan=\"3\">Sparse</th><th colspan=\"3\">Dense</th><th colspan=\"3\">Very Dense</th></tr><tr><th>Density</th><th>Threshold</th><th>NAR</th><th>Density</th><th>Threshold</th><th>NAR</th><th>Density</th><th>Threshold</th><th>NAR</th><th>Density</th><th>Threshold</th><th>NAR</th></tr><tr><td>180533</td><td> 3.32%</td><td>2949</td><td>0.165</td><td> 9.02%</td><td>1024</td><td>0.092</td><td>18.80%</td><td>53</td><td>0.242</td><td>21.88%</td><td>150</td><td>0.084</td></tr><tr><td>186545</td><td> 3.18%</td><td>3274</td><td>0.188</td><td>11.20%</td><td>481</td><td>0.102</td><td>21.30%</td><td>52</td><td>0.242</td><td>25.25%</td><td>116</td><td>0.078</td></tr><tr><td>188145</td><td> 3.20%</td><td>3191</td><td>0.187</td><td>10.66%</td><td>684</td><td>0.099</td><td>22.95%</td><td>46</td><td>0.235</td><td>27.54%</td><td>60</td><td>0.074</td></tr><tr><td>152427</td><td> 3.32%</td><td>3184</td><td>0.230</td><td>12.17%</td><td>437</td><td>0.094</td><td>24.09%</td><td>36</td><td>0.204</td><td>26.03%</td><td>73</td><td>0.074</td></tr><tr><td>146735</td><td> 3.44%</td><td>2887</td><td>0.244</td><td>12.82%</td><td>317</td><td>0.100</td><td>24.29%</td><td>45</td><td>0.222</td><td>26.20%</td><td>134</td><td>0.087</td></tr><tr><td>126426</td><td> 3.04%</td><td>3334</td><td>0.226</td><td>12.79%</td><td>357</td><td>0.107</td><td>24.72%</td><td>48</td><td>0.233</td><td>29.31%</td><td>66</td><td>0.083</td></tr><tr><td>137431</td><td> 2.71%</td><td>3849</td><td>0.193</td><td>12.29%</td><td>477</td><td>0.106</td><td>25.70%</td><td>37</td><td>0.232</td><td>27.93%</td><td>91</td><td>0.070</td></tr><tr><td>144125</td><td> 1.28%</td><td>4596</td><td>0.228</td><td>12.12%</td><td>529</td><td>0.110</td><td>26.47%</td><td>38</td><td>0.213</td><td>28.98%</td><td>60</td><td>0.094</td></tr><tr><td>177140</td><td> 2.90%</td><td>3808</td><td>0.204</td><td>12.91%</td><td>370</td><td>0.117</td><td>27.89%</td><td>40</td><td>0.217</td><td>31.66%</td><td>48</td><td>0.095</td></tr><tr><td>153227</td><td> 3.72%</td><td>3062</td><td>0.234</td><td>12.82%</td><td>497</td><td>0.100</td><td>28.74%</td><td>33</td><td>0.213</td><td>31.12%</td><td>52</td><td>0.093</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = '<table><tr><th rowspan=\"2\" align=\"center\" >Subject</th><th colspan=\"3\">Very Sparse</th>'\n",
    "html += '<th colspan=\"3\">Sparse</th><th colspan=\"3\">Dense</th><th colspan=\"3\">Very Dense</th></tr><tr>'\n",
    "for i in range(4):\n",
    "    html += '<th>Density</th><th>Threshold</th><th>NAR</th>'\n",
    "html += '</tr>'\n",
    "for index, row in thresholds.iterrows():\n",
    "    html += \"<tr><td>%d</td>\" % row['subject']\n",
    "    for suffix in suffixes:\n",
    "        html += \"<td>%5.2f%%</td><td>%d</td>\" % (row['percentage_'+suffix], row['threshold_'+suffix])\n",
    "        html += '<td>%5.3f</td>' % mn.utils.NAR(network[suffix](row['subject']).mania2_network)\n",
    "    html += \"</tr>\"\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency of Adjacent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.correction_type='Adjacent' \"\n",
    "query += f\"AND r.SUBJECT IN {sub_train} AND r.run_id IN {run_id_all} RETURN r.run_id AS run_id, \"\n",
    "query += \"r.SUBJECT as subject, r.is_connected AS is_connected, COUNT(*) AS count\"\n",
    "adjacency_frame = graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_counts = dict()\n",
    "for index, row in adjacency_frame.iterrows():\n",
    "    subject, run_id = row['subject'], row['run_id']\n",
    "    if subject not in adjacency_counts:\n",
    "        adjacency_counts[subject] = dict()\n",
    "    if run_id not in adjacency_counts[subject]:\n",
    "        adjacency_counts[subject][run_id] = {True:0, False:0, 'Total':0}\n",
    "    adjacency_counts[subject][run_id][row['is_connected']] += row['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th rowspan=\"2\" align=\"center\" >Subject</th><th colspan=\"2\">Very Sparse</th><th colspan=\"2\">Sparse</th><th colspan=\"2\">Dense</th><th colspan=\"2\">Very Dense</th></tr><tr><th>% of Adjancent Nodes</th><th>% Adj. Connected</th><th>% of Adjancent Nodes</th><th>% Adj. Connected</th><th>% of Adjancent Nodes</th><th>% Adj. Connected</th><th>% of Adjancent Nodes</th><th>% Adj. Connected</th></tr><tr><td>188145</td><td> 3.26%</td><td>82.38%</td><td> 3.05%</td><td>99.80%</td><td> 3.05%</td><td>100.00%</td><td> 3.05%</td><td>100.00%</td></tr><tr><td>186545</td><td> 3.26%</td><td>82.00%</td><td> 3.06%</td><td>99.90%</td><td> 3.06%</td><td>100.00%</td><td> 3.06%</td><td>100.00%</td></tr><tr><td>180533</td><td> 3.26%</td><td>84.67%</td><td> 2.98%</td><td>99.06%</td><td> 2.98%</td><td>100.00%</td><td> 2.98%</td><td>100.00%</td></tr><tr><td>177140</td><td> 3.26%</td><td>75.71%</td><td> 3.05%</td><td>99.69%</td><td> 3.05%</td><td>100.00%</td><td> 3.05%</td><td>100.00%</td></tr><tr><td>153227</td><td> 3.26%</td><td>86.86%</td><td> 3.08%</td><td>100.00%</td><td> 3.08%</td><td>100.00%</td><td> 3.08%</td><td>100.00%</td></tr><tr><td>152427</td><td> 3.26%</td><td>81.71%</td><td> 3.05%</td><td>99.69%</td><td> 3.05%</td><td>100.00%</td><td> 3.05%</td><td>100.00%</td></tr><tr><td>146735</td><td> 3.26%</td><td>82.10%</td><td> 3.03%</td><td>99.90%</td><td> 3.03%</td><td>100.00%</td><td> 3.03%</td><td>100.00%</td></tr><tr><td>144125</td><td> 3.26%</td><td>36.61%</td><td> 2.98%</td><td>99.58%</td><td> 2.98%</td><td>100.00%</td><td> 2.98%</td><td>99.90%</td></tr><tr><td>137431</td><td> 3.26%</td><td>72.29%</td><td> 3.07%</td><td>99.80%</td><td> 3.07%</td><td>100.00%</td><td> 3.07%</td><td>99.90%</td></tr><tr><td>126426</td><td> 3.26%</td><td>75.52%</td><td> 2.97%</td><td>99.90%</td><td> 2.97%</td><td>100.00%</td><td> 2.97%</td><td>100.00%</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = '<table><tr><th rowspan=\"2\" align=\"center\" >Subject</th><th colspan=\"2\">Very Sparse</th>'\n",
    "html += '<th colspan=\"2\">Sparse</th><th colspan=\"2\">Dense</th><th colspan=\"2\">Very Dense</th></tr><tr>'\n",
    "for i in range(4):\n",
    "    html += '<th>% of Adjancent Nodes</th><th>% Adj. Connected</th>'\n",
    "html += '</tr>'\n",
    "for subject, values in adjacency_counts.items():\n",
    "    html += f'<tr><td>{subject}</td>'\n",
    "    for suffix in suffixes:\n",
    "        counts = values[f'Constantine_{suffix}_v2']\n",
    "        pct_adj = (counts[True] + counts[False]) / 322.20\n",
    "        pct_con = counts[True] * 100. / (counts[True] + counts[False])\n",
    "        html += '<td>%5.2f%%</td><td>%5.2f%%</td>' % (pct_adj, pct_con)\n",
    "    html += '</tr>'\n",
    "html += '</table>'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.correction_type='Adjacent' \"\n",
    "query += f\"AND r.SUBJECT IN {sub_train} AND r.run_id IN {run_id_all} \"\n",
    "query += \"WITH r.run_id AS run_id, n.name AS source, m.name AS target, COUNT(*) AS num_subjects \"\n",
    "query += \" RETURN run_id, num_subjects, COUNT(*) AS num_links\"\n",
    "adjacency_count = graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_counts = dict()\n",
    "for index, row in adjacency_count.iterrows():\n",
    "    run_id = str(row['run_id'].split('_')[1])\n",
    "    if run_id not in adjacency_counts:\n",
    "        adjacency_counts[run_id] = np.zeros(len(sub_train)+1, dtype=int)\n",
    "    adjacency_counts[run_id][row['num_subjects']] = row['num_links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc36bbffd5a48ae84ecbad9867eeda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x_axis = np.arange(0, len(sub_train)+1)\n",
    "plt.bar(x_axis-0.3, adjacency_counts['vsparse'], width=0.2, label='Very Sparse')\n",
    "plt.bar(x_axis-0.1, adjacency_counts['sparse'], width=0.2, label='Sparse')\n",
    "plt.bar(x_axis+0.1, adjacency_counts['dense'], width=0.2, label='Dense')\n",
    "plt.bar(x_axis+0.3, adjacency_counts['vdense'], width=0.2, label='Very Dense')\n",
    "plt.legend()\n",
    "plt.title('Consistency of Adjacency of Links')\n",
    "plt.xlabel('# Subjects in which the Link is Adjacent')\n",
    "plt.ylabel('# of such Links')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.correction_type='Adjacent' \"\n",
    "query += f\"AND r.SUBJECT IN {sub_train} AND r.run_id IN {run_id_all} AND r.is_connected=TRUE \"\n",
    "query += \"WITH r.run_id AS run_id, n.name AS source, m.name AS target, COUNT(*) AS num_subjects \"\n",
    "query += \" RETURN run_id, num_subjects, COUNT(*) AS num_links\"\n",
    "adj_connected_count = graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_connected_counts = dict()\n",
    "for index, row in adj_connected_count.iterrows():\n",
    "    run_id = str(row['run_id'].split('_')[1])\n",
    "    if run_id not in adj_connected_counts:\n",
    "        adj_connected_counts[run_id] = np.zeros(len(sub_train)+1, dtype=int)\n",
    "    adj_connected_counts[run_id][row['num_subjects']] = row['num_links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982af0f9bb084091890806e897185841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x_axis = np.arange(0, len(sub_train)+1)\n",
    "plt.bar(x_axis-0.3, adj_connected_counts['vsparse'], width=0.2, label='Very Sparse')\n",
    "plt.bar(x_axis-0.1, adj_connected_counts['sparse'], width=0.2, label='Sparse')\n",
    "plt.bar(x_axis+0.1, adj_connected_counts['dense'], width=0.2, label='Dense')\n",
    "plt.bar(x_axis+0.3, adj_connected_counts['vdense'], width=0.2, label='Very Dense')\n",
    "plt.legend()\n",
    "plt.title('Consistency of Connected Adjacent Links')\n",
    "plt.xlabel('# Subjects in which the Link is Adjacent and Connected')\n",
    "plt.ylabel('# of such Links')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mania Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_manias_cache = dict()\n",
    "def plot_manias(subject):\n",
    "    subject = int(subject)\n",
    "    if subject not in plot_manias_cache:\n",
    "        dense_sub, sparse_sub = dense_network(subject), sparse_network(subject)\n",
    "        vdense_sub, vsparse_sub = vdense_network(subject), vsparse_network(subject)\n",
    "        _,den_1,nar_1,t_1 = mn.utils.networks.mania_on_mat(dense_sub.matrix1)\n",
    "        _,den_d,nar_d,t_d = mn.utils.networks.mania_on_mat(dense_sub.matrix2)\n",
    "        _,den_s,nar_s,t_s = mn.utils.networks.mania_on_mat(sparse_sub.matrix2)\n",
    "        _,den_vd,nar_vd,t_vd = mn.utils.networks.mania_on_mat(vdense_sub.matrix2)\n",
    "        _,den_vs,nar_vs,t_vs = mn.utils.networks.mania_on_mat(vsparse_sub.matrix2)\n",
    "        threshold_1 = dense_sub.threshold1\n",
    "        threshold_d, threshold_vd = dense_sub.threshold2, vdense_sub.threshold2\n",
    "        threshold_s, threshold_vs = sparse_sub.threshold2, vsparse_sub.threshold2\n",
    "        idx_1, idx_d, idx_s = np.argmin(nar_1), np.argmin(nar_d), np.argmin(nar_s)\n",
    "        idx_vd, idx_vs = np.argmin(nar_vd), np.argmin(nar_vs)\n",
    "        density_1, density_d, density_s = den_1[idx_1], den_d[idx_d], den_s[idx_s]\n",
    "        density_vd, density_vs = den_vd[idx_vd], den_vs[idx_vs]\n",
    "        nar_value_1, nar_value_d, nar_value_s = nar_1[idx_1], nar_d[idx_d], nar_s[idx_s]\n",
    "        nar_value_vd, nar_value_vs = nar_vd[idx_vd], nar_vs[idx_vs]\n",
    "        d = dict()\n",
    "        d['den_1'], d['den_d'], d['den_s'], d['den_vd'], d['den_vs'] = den_1, den_d, den_s, den_vd, den_vs\n",
    "        d['nar_1'], d['nar_d'], d['nar_s'], d['nar_vd'], d['nar_vs'] = nar_1, nar_d, nar_s, nar_vd, nar_vs\n",
    "        d['density_1'], d['density_d'], d['density_s'], d['density_vd'], d['density_vs'] = density_1, density_d, density_s, density_vd, density_vs\n",
    "        d['nar_value_1'], d['nar_value_d'], d['nar_value_s'], d['nar_value_vd'], d['nar_value_vs'] = nar_value_1, nar_value_d, nar_value_s, nar_value_vd, nar_value_vs\n",
    "        d['t_1'], d['t_d'], d['t_s'], d['t_vd'], d['t_vs'] = t_1, t_d, t_s, t_vd, t_vs\n",
    "        d['threshold_1'], d['threshold_d'], d['threshold_s'], d['threshold_vd'], d['threshold_vs'] = threshold_1, threshold_d, threshold_s, threshold_vd, threshold_vs\n",
    "        plot_manias_cache[subject] = d\n",
    "    else:\n",
    "        d = plot_manias_cache[subject]\n",
    "        den_1, den_d, den_s, den_vd, den_vs = d['den_1'], d['den_d'], d['den_s'], d['den_vd'], d['den_vs']\n",
    "        nar_1, nar_d, nar_s, nar_vd, nar_vs = d['nar_1'], d['nar_d'], d['nar_s'], d['nar_vd'], d['nar_vs']\n",
    "        density_1, density_d, density_s, density_vd, density_vs = d['density_1'], d['density_d'], d['density_s'], d['density_vd'], d['density_vs']\n",
    "        nar_value_1, nar_value_d, nar_value_s, nar_value_vd, nar_value_vs = d['nar_value_1'], d['nar_value_d'], d['nar_value_s'], d['nar_value_vd'], d['nar_value_vs']\n",
    "        t_1, t_d, t_s, t_vd, t_vs = d['t_1'], d['t_d'], d['t_s'], d['t_vd'], d['t_vs']\n",
    "        threshold_1, threshold_d, threshold_s, threshold_vd, threshold_vs = d['threshold_1'], d['threshold_d'], d['threshold_s'], d['threshold_vd'], d['threshold_vs']\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(10,6))\n",
    "    ax[0].plot(den_1,nar_1,'b-',lw=2,label='MANIA 1')\n",
    "    ax[0].plot(den_vs,nar_vs,'c-',lw=2,label='Very Sparse')\n",
    "    ax[0].plot(den_s,nar_s,'g-',lw=2,label='Sparse')\n",
    "    ax[0].plot(den_d,nar_d,'r-',lw=2,label='Dense')\n",
    "    ax[0].plot(den_vd,nar_vd,'m-',lw=2,label='Very Dense')\n",
    "    ax[0].axvline(density_1, 0, 1, color='b', linestyle='dashed', lw=1)\n",
    "    ax[0].axvline(density_d, 0, 1, color='r', linestyle='dashed', lw=1)\n",
    "    ax[0].axvline(density_s, 0, 1, color='g', linestyle='dashed', lw=1)\n",
    "    ax[0].axvline(density_vd, 0, 1, color='c', linestyle='dashed', lw=1)\n",
    "    ax[0].axvline(density_vs, 0, 1, color='k', linestyle='dashed', lw=1)\n",
    "    ax[0].axhline(nar_value_1, 0, 1, color='b', linestyle='dashed', lw=1)\n",
    "    ax[0].axhline(nar_value_d, 0, 1, color='r', linestyle='dashed', lw=1)\n",
    "    ax[0].axhline(nar_value_s, 0, 1, color='g', linestyle='dashed', lw=1)\n",
    "    ax[0].axhline(nar_value_vd, 0, 1, color='m', linestyle='dashed', lw=1)\n",
    "    ax[0].axhline(nar_value_vs, 0, 1, color='c', linestyle='dashed', lw=1)\n",
    "    ax[0].set_xlabel('density')\n",
    "    ax[0].set_ylabel('NAR')\n",
    "    ax[1].plot(t_1,den_1,'b-',lw=2,label='MANIA 1')\n",
    "    ax[1].plot(t_vs,den_vs,'c-',lw=2,label='Very Sparse')\n",
    "    ax[1].plot(t_s,den_s,'g-',lw=2,label='Sparse')\n",
    "    ax[1].plot(t_d,den_d,'r-',lw=2,label='Dense')\n",
    "    ax[1].plot(t_vd,den_vd,'m-',lw=2,label='Very Dense')\n",
    "    ax[1].set_xlabel('Threshold')\n",
    "    ax[1].set_ylabel('Density')\n",
    "    ax[1].axvline(threshold_1, color='b', linestyle='dashed', lw=1)\n",
    "    ax[1].axvline(threshold_d, color='r', linestyle='dashed', lw=1)\n",
    "    ax[1].axvline(threshold_s, color='g', linestyle='dashed', lw=1)\n",
    "    ax[1].axvline(threshold_vd, color='m', linestyle='dashed', lw=1)\n",
    "    ax[1].axvline(threshold_vs, color='c', linestyle='dashed', lw=1)\n",
    "    ax[1].axhline(density_1, 0, 1, color='b', linestyle='dashed', lw=1)\n",
    "    ax[1].axhline(density_d, 0, 1, color='r', linestyle='dashed', lw=1)\n",
    "    ax[1].axhline(density_s, 0, 1, color='g', linestyle='dashed', lw=1)\n",
    "    ax[1].axhline(density_vd, 0, 1, color='c', linestyle='dashed', lw=1)\n",
    "    ax[1].axhline(density_vs, 0, 1, color='k', linestyle='dashed', lw=1)\n",
    "    plt.suptitle(f'Subject: {subject}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e203fababd7142dfae97ccc304aedb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='subject', options=('126426', '137431', '144125', '146735', '152427â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_manias(subject)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_manias, subject=[str(x) for x in sub_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(corr_type, reg_type, sparse):\n",
    "    if corr_type == 'Null':\n",
    "        return 'Null'\n",
    "    if corr_type == 'Adjacent':\n",
    "        return 'Adjacent'\n",
    "    if corr_type in ['Bad regressor', 'No Envelope No regress']:\n",
    "        return 'No Correction'\n",
    "    if corr_type == 'Regress' and reg_type == 'independent':\n",
    "        return 'Independent'\n",
    "    if sparse:\n",
    "        if reg_type in ['direction1', 'direction2', 'poolAll', 'poolEnvelopes']:\n",
    "            return 'No Correction'\n",
    "    else:\n",
    "        if reg_type == 'direction1' or reg_type == 'direction2':\n",
    "            return 'one direction'\n",
    "        if reg_type == 'poolAll' or reg_type == 'poolEnvelopes':\n",
    "            return reg_type\n",
    "    if corr_type == 'No Correction':\n",
    "        return 'No Correction'\n",
    "    print('Error while evaluating: ', corr_type, reg_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter(algo_type):\n",
    "    assert (algo_type in types)\n",
    "    if algo_type in ['Null', 'Adjacent'] :\n",
    "        return f\"r.correction_type='{algo_type}'\"\n",
    "    if algo_type == 'No Correction':\n",
    "        return \"r.correction_type IN ['Bad regressor', 'No Envelope No regress', 'No Correction']\"\n",
    "    if algo_type == 'Independent':\n",
    "        return \"(r.correction_type='Regress' AND r.regressor_type='independent')\"\n",
    "    if algo_type == 'one direction':\n",
    "        return \"(r.correction_type IN ['No Envelope but regress', 'Regress'] AND r.regressor_type IN ['direction1', 'direction2'])\"\n",
    "    if algo_type == 'poolAll':\n",
    "        return \"(r.correction_type IN ['No Envelope but regress', 'Regress'] AND r.regressor_type = 'poolAll')\"\n",
    "    string = \"(\"\n",
    "    first = True\n",
    "    for (corr_type, reg_type) in types[algo_type]:\n",
    "        if not first:\n",
    "            string += \"OR \"\n",
    "        else:\n",
    "            first = False\n",
    "        string += f\"(r.correction_type='{corr_type}' AND r.regressor_type='{reg_type}') \"\n",
    "    string += \")\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'Null':set(), 'Adjacent':set(), 'No Correction':set(), 'Independent':set(), 'one direction':set(), 'poolAll':set()}\n",
    "def get_counts_by_type(run_id, subjects):\n",
    "    query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.SUBJECT IN [{joini(subjects)}] \"\n",
    "    query += f\"AND r.is_connected=TRUE AND r.run_id='{run_id}' \"\n",
    "    query += \"RETURN r.correction_type AS correction_type, r.regressor_type AS regressor_type, COUNT(*) AS counts\"\n",
    "    counts_true = graph.run(query).to_ndarray()\n",
    "    query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.SUBJECT IN [{joini(subjects)}] \"\n",
    "    query += f\"AND r.is_connected=FALSE AND r.run_id='{run_id}' \"\n",
    "    query += f\"RETURN r.correction_type AS correction_type, r.regressor_type AS regressor_type, COUNT(*) AS counts\"\n",
    "    counts_false = graph.run(query).to_ndarray()\n",
    "    counts = dict()\n",
    "    for row in counts_true:\n",
    "        algo_type = get_type(row[0], row[1], 'sparse' in run_id)\n",
    "        types[algo_type].add((row[0], row[1]))\n",
    "        if algo_type not in counts:\n",
    "            counts[algo_type] = {True:0, False:0}\n",
    "        counts[algo_type][True] += int(row[2])\n",
    "    for row in counts_false:\n",
    "        algo_type = get_type(row[0], row[1], 'sparse' in run_id)\n",
    "        types[algo_type].add((row[0], row[1]))\n",
    "        if algo_type not in counts:\n",
    "            counts[algo_type] = {True:0, False:0}\n",
    "        counts[algo_type][False] += int(row[2])\n",
    "    for algo_type in counts:\n",
    "        counts[algo_type]['total'] = counts[algo_type][True] + counts[algo_type][False]\n",
    "    total = 0\n",
    "    for algo_type in counts:\n",
    "        total += counts[algo_type]['total']\n",
    "    assert total == len(subjects)*32220\n",
    "    for algo_type in counts:\n",
    "        counts[algo_type]['fraction'] = counts[algo_type]['total']/float(total)\n",
    "        counts_all = counts[algo_type][True] + counts[algo_type][False]\n",
    "        counts[algo_type]['pct_connected'] = counts[algo_type][True]*100./counts_all\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_type_sparse = get_counts_by_type(run_id_sparse, sub_train)\n",
    "by_type_vdense = get_counts_by_type(run_id_vdense, sub_train)\n",
    "by_type_dense = get_counts_by_type(run_id_dense, sub_train)\n",
    "by_type_vsparse = get_counts_by_type(run_id_vsparse, sub_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th rowspan=\"2\">Type</th><th colspan=\"2\">Very Sparse</th><th colspan=\"2\">Sparse</th><th colspan=\"2\">Dense</th><th colspan=\"2\">Very Dense</th></tr><tr><th>Fraction of Total</th><th>% Connected</th><th>Fraction of Total</th><th>% Connected</th><th>Fraction of Total</th><th>% Connected</th><th>Fraction of Total</th><th>% Connected</th></tr><tr><td>Adjacent</td><td> 3.26%</td><td>75.99%</td><td> 3.03%</td><td>99.73%</td><td> 3.03%</td><td>100.00%</td><td> 3.03%</td><td>99.98%</td></tr><tr><td>Independent</td><td> 9.05%</td><td> 5.66%</td><td> 9.21%</td><td>88.61%</td><td> 9.21%</td><td>93.69%</td><td> 9.21%</td><td>98.40%</td></tr><tr><td>poolAll</td><td> 9.05%</td><td> 5.66%</td><td> 0.00%</td><td> 0.00%</td><td> 1.72%</td><td>65.67%</td><td> 1.72%</td><td>87.98%</td></tr><tr><td>one direction</td><td> 9.05%</td><td> 5.66%</td><td> 0.00%</td><td> 0.00%</td><td>14.33%</td><td>72.51%</td><td>14.33%</td><td>93.23%</td></tr><tr><td>No Correction</td><td>55.78%</td><td> 0.04%</td><td>55.84%</td><td> 1.24%</td><td>39.79%</td><td> 3.29%</td><td>39.79%</td><td> 1.56%</td></tr><tr><td>Null</td><td>31.91%</td><td> 0.00%</td><td>31.91%</td><td> 0.00%</td><td>31.91%</td><td> 0.00%</td><td>31.91%</td><td> 0.00%</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = '<table><tr><th rowspan=\"2\">Type</th><th colspan=\"2\">Very Sparse</th><th colspan=\"2\">Sparse</th>'\n",
    "html += '<th colspan=\"2\">Dense</th><th colspan=\"2\">Very Dense</th></tr><tr>'\n",
    "for i in range(4):\n",
    "    html += '<th>Fraction of Total</th><th>% Connected</th>'\n",
    "html += '</tr>'\n",
    "for algo_type in ['Adjacent', 'Independent', 'poolAll', 'one direction', 'No Correction', 'Null']:\n",
    "    if algo_type in by_type_dense:\n",
    "        dense = by_type_dense[algo_type]\n",
    "    else:\n",
    "        dense = {'fraction':0., 'pct_connected':0.}\n",
    "    if algo_type in by_type_sparse:\n",
    "        sparse = by_type_sparse[algo_type]\n",
    "    else:\n",
    "        sparse = {'fraction':0., 'pct_connected':0.}\n",
    "    if algo_type in by_type_vdense:\n",
    "        vdense = by_type_vdense[algo_type]\n",
    "    else:\n",
    "        dense = {'fraction':0., 'pct_connected':0.}\n",
    "    if algo_type in by_type_vsparse:\n",
    "        vsparse = by_type_vsparse[algo_type]\n",
    "    else:\n",
    "        sparse = {'fraction':0., 'pct_connected':0.}\n",
    "    html += '<tr><td>%s</td>' % algo_type\n",
    "    html += '<td>%5.2f%%</td><td>%5.2f%%</td>' % (vsparse['fraction']*100, vsparse['pct_connected'])\n",
    "    html += '<td>%5.2f%%</td><td>%5.2f%%</td>' % (sparse['fraction']*100, sparse['pct_connected'])\n",
    "    html += '<td>%5.2f%%</td><td>%5.2f%%</td>' % (dense['fraction']*100, dense['pct_connected'])\n",
    "    html += '<td>%5.2f%%</td><td>%5.2f%%</td></tr>' % (vdense['fraction']*100, vdense['pct_connected'])\n",
    "html += '</table>'\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Sample Links from Different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_links(subjects, run_id, algo_type, num_links = 10):\n",
    "    query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.run_id='{run_id}' \"\n",
    "    query += f\"AND r.SUBJECT IN {subjects} AND {get_filter(algo_type)} \"\n",
    "    query += \"WITH n.name AS source, m.name AS target, r.SUBJECT AS subject \"\n",
    "    query += f\"RETURN subject, source, target LIMIT {num_links}\"\n",
    "    return graph.run(query).to_data_frame()\n",
    "\n",
    "links_sparse = dict()\n",
    "for algo_type in types:\n",
    "    links_sparse[algo_type] = get_sample_links(sub_train, run_id_sparse, algo_type, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo_type in types:\n",
    "    display(HTML(f'<h2>{algo_type}</h2>'))\n",
    "    for idx, row in links_sparse[algo_type].iterrows():\n",
    "        pair = dense_network(row['subject'])(row['source'], row['target'],pair=True)\n",
    "        print(row)\n",
    "        print(pair.st1.regressor.kind, pair.st2.regressor.kind)\n",
    "        pair.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_links(subjects, run_id, algo_type, num_links = 10):\n",
    "    query = f\"MATCH (n:ROI)-[r:MANIA2]->(m:ROI) WHERE n.name STARTS WITH 'L' AND r.run_id='{run_id}' \"\n",
    "    query += f\"AND r.SUBJECT IN {subjects} AND {get_filter(algo_type)} \"\n",
    "    query += \"WITH n.name AS source, m.name AS target, r.SUBJECT AS subject \"\n",
    "    query += f\"RETURN subject, source, target LIMIT {num_links}\"\n",
    "    return graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Dense version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_dense = dict()\n",
    "for algo_type in types:\n",
    "    display(HTML(f'<h3>{algo_type}</h3>'))\n",
    "    links_dense[algo_type] = get_sample_links(sub_train, run_id_dense, algo_type, 4)\n",
    "    for idx, row in links[algo_type].iterrows():\n",
    "        pair = dense_network(row['subject'])(row['source'], row['target'],pair=True)\n",
    "        print(pair.st1.regressor.kind, pair.st2.regressor.kind)\n",
    "        pair.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Sparse Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_sparse = dict()\n",
    "for algo_type in types:\n",
    "    display(HTML(f'<h3>{algo_type}</h3>'))\n",
    "    links_sparse[algo_type] = get_sample_links(sub_train, run_id_sparse, algo_type, 4)\n",
    "    for idx, row in links_sparse[algo_type].iterrows():\n",
    "        pair = sparse_network(row['subject'])(row['source'], row['target'],pair=True)\n",
    "        print(pair.st1.regressor.kind, pair.st2.regressor.kind)\n",
    "        pair.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
